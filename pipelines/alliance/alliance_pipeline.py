import argparse
import concurrent.futures
import datetime
import json
import logging
import os
import time
import traceback
from string import Template

from genedescriptions.commons import DataType
from genedescriptions.config_parser import GenedescConfigParser
from genedescriptions.descriptions_writer import DescriptionsWriter
from genedescriptions.gene_description import GeneDescription
from genedescriptions.precanned_modules import set_expression_module, set_gene_ontology_module, set_disease_module, \
    set_alliance_human_orthology_module
from pipelines.alliance.alliance_data_manager import AllianceDataManager, provider_to_expression_curie_prefix

logger = logging.getLogger(__name__)

SPECIES_BY_PROVIDER = {
    'WB': 'Caenorhabditis elegans',
    'ZFIN': 'Danio rerio',
    'FB': 'Drosophila melanogaster',
    'HUMAN': 'Homo sapiens',
    'MGI': 'Mus musculus',
    'RGD': 'Rattus norvegicus',
    'SGD': 'Saccharomyces cerevisiae',
    'XBXL': 'Xenopus laevis',
    'XBXT': 'Xenopus tropicalis'
}

TAXON_BY_PROVIDER = {
    'WB': '6239',
    'ZFIN': '7955',
    'FB': '7227',
    'HUMAN': '9606',
    'MGI': '10090',
    'RGD': '10116',
    'SGD': '559292',
    'XBXL': '8355',
    'XBXT': '8364'
}

FILE_HEADER_TEMPLATE = Template("""\
##########################################################################
#
# Data type: $file_type
# Data format: $data_format
# README: $readme
# Source: Alliance of Genome Resources (Alliance)
# Source URL: https://www.alliancegenome.org/downloads
# Help Desk: help@alliancegenome.org
# TaxonIDs: NCBITaxon:$taxon_id
# Species: $species
# Alliance Database Version: $database_version
# Date file generated (UTC): $gen_time
#
##########################################################################""")

FILE_README = (
    "This file contains the following fields: gene ID, gene name, and "
    "gene description. The gene descriptions are generated by an algorithm "
    "developed by the Alliance that uses highly structured gene data such as "
    "associations to various ontology terms (e.g., Gene Ontology terms) and "
    "the Alliance strict orthology set. The original set of ontology terms "
    "that a gene is annotated to may have been trimmed to an ancestor term "
    "in the ontology, in order to balance readability with the amount of "
    "information in the description. The complete set of annotations to any "
    "gene in this file may be found in the relevant data tables on the "
    "Alliance gene page."
)


def load_all_data_for_provider(data_manager: AllianceDataManager, data_provider: str, species_taxon: str):
    logger.info(f"Loading GAF file for {data_provider}")
    data_manager.load_annotations(associations_type=DataType.GO, taxon_id=species_taxon, provider=data_provider)
    logger.info(f"Loading disease annotations for {data_provider}")
    data_manager.load_annotations(associations_type=DataType.DO, taxon_id=species_taxon, provider=data_provider)
    if data_provider in provider_to_expression_curie_prefix:
        logger.info(f"Loading anatomy ontology data for {data_provider}")
        data_manager.load_ontology(ontology_type=DataType.EXPR, provider=data_provider)

        logger.info(f"Loading expression annotations for {data_provider}")
        data_manager.load_annotations(associations_type=DataType.EXPR, taxon_id=species_taxon,
                                      provider=data_provider)

    logger.info(f"Loading gene data for {data_provider}")
    data_manager.load_gene_data(species_taxon=species_taxon)

    # Prepend 'RGD:' to all gene ids if provider is HUMAN
    if data_provider == "HUMAN":
        for gene_id in list(data_manager.gene_data.keys()):
            gene = data_manager.gene_data[gene_id]
            new_gene_id = f"RGD:{gene.id}"
            data_manager.gene_data[new_gene_id] = gene._replace(id=new_gene_id)
            del data_manager.gene_data[gene_id]


def generate_gene_descriptions(data_manager: AllianceDataManager, best_orthologs, data_provider: str,
                               conf_parser: GenedescConfigParser, json_desc_writer: DescriptionsWriter):
    for gene in data_manager.get_gene_data():
        # For HUMAN genes, gene.id has 'RGD:' prefix for annotation matching
        # but output files should use the original HGNC ID
        output_gene_id = gene.id
        if data_provider == "HUMAN" and gene.id.startswith("RGD:"):
            output_gene_id = gene.id[4:]
        gene_desc = GeneDescription(gene_id=output_gene_id,
                                    gene_name=gene.name,
                                    add_gene_name=False,
                                    config=conf_parser)
        set_gene_ontology_module(dm=data_manager, conf_parser=conf_parser, gene_desc=gene_desc, gene=gene)
        if data_provider in provider_to_expression_curie_prefix:
            set_expression_module(df=data_manager,
                                  conf_parser=conf_parser,
                                  gene_desc=gene_desc,
                                  gene=gene)
        set_disease_module(df=data_manager, conf_parser=conf_parser, gene_desc=gene_desc, gene=gene,
                           human=data_provider == "HUMAN")
        if gene.id in best_orthologs:
            gene_desc.stats.set_best_orthologs = best_orthologs[gene.id][0]
            set_alliance_human_orthology_module(orthologs=best_orthologs[gene.id][0],
                                                excluded_orthologs=best_orthologs[gene.id][1],
                                                gene_desc=gene_desc,
                                                config=conf_parser)
        json_desc_writer.add_gene_desc(gene_desc)


def add_header_to_file(file_path: str, data_format: str, data_provider: str):
    """Prepend a standard Alliance header to a generated file."""
    alliance_release = os.environ.get("ALLIANCE_RELEASE", "")
    header = FILE_HEADER_TEMPLATE.substitute(
        file_type="Gene Descriptions",
        data_format=data_format,
        readme=FILE_README,
        taxon_id=TAXON_BY_PROVIDER.get(data_provider, ""),
        species=SPECIES_BY_PROVIDER.get(data_provider, ""),
        database_version=alliance_release,
        gen_time=datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M")
    )
    with open(file_path, "r") as original:
        data = original.read()
    with open(file_path, "w") as modified:
        modified.write(header + "\n\n" + data)


def save_gene_descriptions(data_manager: AllianceDataManager, json_desc_writer: DescriptionsWriter, data_provider: str):
    base_path = f"pipelines/alliance/generated_descriptions/{data_provider}"
    alliance_release = os.environ.get("ALLIANCE_RELEASE", "")
    release_version = ".".join(alliance_release.split(".")[0:2])

    json_desc_writer.overall_properties.species = data_provider
    json_desc_writer.overall_properties.release_version = release_version
    json_desc_writer.overall_properties.date = datetime.date.today().isoformat()

    json_desc_writer.write_json(file_path=base_path + ".json",
                                include_single_gene_stats=True,
                                data_manager=data_manager)
    json_desc_writer.write_tsv(file_path=base_path + ".tsv")
    json_desc_writer.write_plain_text(file_path=base_path + ".txt")

    add_header_to_file(base_path + ".tsv", "tsv", data_provider)
    add_header_to_file(base_path + ".txt", "txt", data_provider)

    with open(base_path + "_stats.json", "w") as stats_file:
        json.dump(vars(json_desc_writer.general_stats), stats_file)
    logger.info(f"Saved description files for {data_provider}")

    gene_desc_pairs = [
        (gd.gene_id, gd.description)
        for gd in json_desc_writer.data if gd.description
    ]
    data_manager.write_gene_description_notes(gene_desc_pairs)
    logger.info(f"Wrote gene description notes to database for {data_provider}")


def process_provider(data_provider, species_taxon, data_manager, conf_parser):
    logger.info(f"Processing provider: {data_provider}")
    json_desc_writer = DescriptionsWriter()

    logger.info(f"Loading all data for {data_provider}")
    load_all_data_for_provider(data_manager, data_provider, species_taxon)
    logger.info(f"Loading best human orthologs for {data_provider}")

    best_orthologs = {}
    if data_provider != "HUMAN":
        best_orthologs = data_manager.get_best_human_orthologs(species_taxon=species_taxon)

    logger.info(f"Generating text summaries for {data_provider}")
    generate_gene_descriptions(data_manager, best_orthologs, data_provider, conf_parser, json_desc_writer)

    logger.info(f"Saving gene descriptions for {data_provider}")
    save_gene_descriptions(data_manager, json_desc_writer, data_provider)


def main():
    parser = argparse.ArgumentParser(description="Generate gene descriptions for wormbase")
    parser.add_argument("-c", "--config-file", metavar="config_file", dest="config_file", type=str,
                        default="config.yml", help="configuration file. Default ./config.yaml")
    parser.add_argument("-L", "--log-level", dest="log_level",
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], default="INFO",
                        help="set the logging level")
    parser.add_argument("--parallel", dest="parallel", action="store_true",
                        help="Run providers in parallel")
    parser.add_argument("--max-workers", dest="max_workers", type=int, default=None,
                        help="Maximum number of parallel executions (default: number of CPUs)")

    args = parser.parse_args()
    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s: %(message)s')
    logging.getLogger(__name__).setLevel(logging.getLevelName(args.log_level))

    start_time = time.time()
    conf_parser = GenedescConfigParser(args.config_file)

    data_manager = AllianceDataManager(config=conf_parser)

    logger.info("Loading data providers")
    data_providers = data_manager.load_data_providers()

    logger.info("Loading GO ontology")
    data_manager.load_ontology(ontology_type=DataType.GO)

    logger.info("Loading DO ontology")
    data_manager.load_ontology(ontology_type=DataType.DO)

    logger.info("Deleting existing automated gene descriptions")
    data_manager.delete_all_automated_gene_descriptions()

    # Close DB connection before spawning subprocesses - each subprocess will create its own
    # This is necessary because SQLAlchemy connections can't be pickled
    data_manager.close()

    if args.parallel:
        logger.info("Processing data providers in parallel")
        with concurrent.futures.ProcessPoolExecutor(max_workers=args.max_workers) as executor:
            futures = [
                executor.submit(process_provider, data_provider, species_taxon, data_manager, conf_parser)
                for data_provider, species_taxon in data_providers
            ]
            for future in concurrent.futures.as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"Error processing data provider: {e}")
                    logger.error(traceback.format_exc())
    else:
        logger.info("Processing data providers sequentially")
        for data_provider, species_taxon in data_providers:
            process_provider(data_provider, species_taxon, data_manager, conf_parser)

    elapsed_time = time.time() - start_time
    formatted_time = time.strftime("%H:%M:%S", time.gmtime(elapsed_time))
    logger.info(f"All data providers processed successfully in {formatted_time}")


if __name__ == '__main__':
    main()
